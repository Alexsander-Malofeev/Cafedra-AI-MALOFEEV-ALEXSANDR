# Отчёт по домашнему заданию HW07: Кластеризация

## 1. Datasets
Выбраны 3 датасета из 4:
S07-hw-dataset-01.csv
S07-hw-dataset-02.csv
S07-hw-dataset-03.csv

### 1.1 Dataset A
Файл: S07-hw-dataset-01.csv
Размер: 12000 строк, 9 столбцов
Признаки: все числовые (8 float64, 1 int64)
Пропуски: обработаны через SimpleImputer (стратегия median)
"Подлости" датасета: разные шкалы признаков, шумовые признаки, требует масштабирования

### 1.2 Dataset B
Файл: S07-hw-dataset-02.csv
Размер: 8000 строк, 4 столбца
Признаки: все числовые (3 float64, 1 int64)
Пропуски: обработаны через SimpleImputer (стратегия median)
"Подлости" датасета: нелинейная структура, наличие выбросов, шумовой признак

### 1.3 Dataset C
Файл: S07-hw-dataset-03.csv
Размер: 15000 строк, 5 столбцов
Признаки: все числовые (4 float64, 1 int64)
Пропуски: обработаны через SimpleImputer (стратегия median)
"Подлости" датасета: кластеры разной плотности, фоновый шум, сложность выбора eps

## 2. Protocol
Использовался честный unsupervised-протокол без использования разметки.


**Препроцессинг:** 
- SimpleImputer со стратегией 'median' для обработки пропусков
- StandardScaler для масштабирования всех числовых признаков
- Категориальные признаки отсутствуют (выбраны датасеты 01, 02, 03 без категориальных признаков)

**Поиск гиперпараметров:**
- KMeans: диапазон k от 2 до 20, выбор по максимуму silhouette score
- DBSCAN: диапазон eps от 0.1 до 3.0 с шагом 0.2, min_samples=5, выбор по максимуму silhouette score
- Agglomerative: диапазон k от 2 до 10, методы linkage ['ward', 'complete', 'average'], выбор по максимуму silhouette score

**Метрики:** silhouette_score (больше=лучше), davies_bouldin_score (меньше=лучше), calinski_harabasz_score (больше=лучше)
Для DBSCAN метрики считались только для не-шумовых точек (label != -1)

**Визуализация:** PCA(2D) для всех датасетов и методов

## 3. Models
На каждом датасете сравнивались следующие модели и параметры.


**Датасет 01:**
- KMeans: поиск k (2-20), random_state=42, n_init=10
- DBSCAN: поиск eps (0.1-3.0), min_samples=5

**Датасет 02:**
- KMeans: поиск k (2-20), random_state=42, n_init=10
- DBSCAN: поиск eps (0.1-3.0), min_samples=5

**Датасет 03:**
- KMeans: поиск k (2-20), random_state=42, n_init=10
- AgglomerativeClustering: поиск k (2-10) и лучшего linkage метода

## 4. Results
Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A
Лучший метод и параметры: DBSCAN, eps=1.70, min_samples=5
Метрики: silhouette=0.5216, DB=0.6853, CH=11786.95
Если был DBSCAN: доля шума 0.00% (нет шума)
Коротко: DBSCAN показал те же метрики, что и KMeans, но не требует задания числа кластеров

### 4.2 Dataset B
Лучший метод и параметры: KMeans, k=2, random_state=42
Метрики: silhouette=0.3069, DB=1.3235, CH=3573.39
Если был DBSCAN: доля шума 7.24%
Коротко: KMeans лучше справился с данным датасетом, DBSCAN выделил слишком много кластеров (5) с шумом

### 4.3 Dataset C
Лучший метод и параметры: AgglomerativeClustering, k=2, linkage='average'
Метрики: silhouette=0.4253, DB=0.8138, CH=8.94
Коротко: Agglomerative значительно превзошел KMeans по silhouette, лучше справился с разной плотностью кластеров

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)
Где KMeans "ломается" и почему? 
- На датасете 02 (silhouette=0.3069) из-за нелинейной структуры
- На датасете 03 (silhouette=0.3155) из-за разной плотности кластеров

Где DBSCAN/иерархическая кластеризация выигрывают и почему?
- DBSCAN на датасете 01 (не требует задания k)
- Agglomerative на датасете 03 (лучше обрабатывает разную плотность через 'average' linkage)

Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)?
1. Масштабирование - критически важно для всех методов
2. Структура данных - линейные vs нелинейные кластеры
3. Наличие шума - DBSCAN на датасете 02 показал 7.24% шума

### 5.2 Устойчивость (обязательно для одного датасета)
Какую проверку устойчивости делали: 5 запусков KMeans с разными random_state на датасете 01
Что получилось: Средний ARI=1.0000, стандартное отклонение=0.0000
Вывод: KMeans показал абсолютную устойчивость на датасете 01 благодаря четкой, хорошо разделимой структуре данных

### 5.3 Интерпретация кластеров
Как вы интерпретировали кластеры: анализ средних значений признаков, визуальная оценка через PCA, сравнение размеров кластеров
3-6 строк выводов: 
Датасет 01 содержит два четко разделенных кластера. 
Датасет 02 имеет два основных кластера с нелинейной структурой. 
Датасет 03 показывает иерархическую структуру, лучше выделяемую агломеративной кластеризацией.

## 6. Conclusion
4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

1. Масштабирование обязательно для distance-based методов кластеризации
2. Выбор алгоритма зависит от структуры данных: KMeans для сферических, DBSCAN для шума, Agglomerative для иерархических структур
3. Silhouette score - эффективная метрика для подбора параметров, но требует осторожной интерпретации
4. Множество метрик дает более полную картину качества кластеризации
5. PCA визуализация - необходимый минимум для оценки результатов
6. Проверка устойчивости важна для оценки надежности алгоритмов
7. Экспериментальный протокол должен включать EDA, препроцессинг, подбор параметров, оценку и визуализацию
8. Обработка шума в DBSCAN требует отдельного рассмотрения при вычислении метрик

---

**Информация о выполнении:**
- Студент: Малофеев Александр Алексеевич
- Дата выполнения: 17.01.2026
- Выбранные датасеты: 01, 02, 03 (без категориальных признаков, поэтому OneHotEncoder не требовался)